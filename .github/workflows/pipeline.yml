name: MTA Subway Static + Realtime + Google Drive

# Prevent scheduled runs from overlapping each other.
# This group is DIFFERENT from backfill's group.
concurrency:
  group: pipeline-${{ github.ref }}
  cancel-in-progress: true

on:
  schedule:
    - cron: "*/10 10-15 * * 1-5"
    - cron: "*/10 20-23 * * 1-5"
    - cron: "*/10 0-1 * * 1-5"
    - cron: "0 12-23 * * 6,0"
    - cron: "0 0-2 * * 0,1"
    - cron: "10 3 * * 0"
  workflow_dispatch: {}

jobs:
  pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: read
      actions: read
    env:
      # Optional: Drive sync (only used if you add rclone steps here later)
      RCLONE_CONF_B64: ${{ secrets.RCLONE_CONF_B64 }}

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install deps
        run: pip install -r requirements.txt

      - name: Install jq/unzip
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq unzip

      # ---- Realtime poller (your existing step) ----
      - name: Run realtime poller
        timeout-minutes: 10
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          trap 'echo "[signal] SIGTERM during realtime poller"; exit 143' SIGTERM
          # Adjust to your entrypoint as needed:
          python pollers/mta_subway_realtime.py

      # ---- Per-run RT artifact (used by backfill fallback) ----
      - name: Upload per-run realtime artifact
        timeout-minutes: 5
        uses: actions/upload-artifact@v4
        with:
          name: subway_realtime_csvs
          path: data/realtime/*.csv
          retention-days: 7

      # ---- Single DAILY artifact (fast path for backfill) ----
      - name: Compute DATE in ET
        run: echo "DATE=$(TZ=America/New_York date +%F)" >> $GITHUB_ENV

      - name: Consolidate today's realtime CSVs
        timeout-minutes: 5
        run: |
          mkdir -p "data/realtime/${DATE}"
          cp -n data/realtime/subway_rt_*.csv "data/realtime/${DATE}/" || true
          ls -lh "data/realtime/${DATE}" || true

      - name: Publish per-day merged artifact
        timeout-minutes: 5
        uses: actions/upload-artifact@v4
        with:
          name: rt_day_${{ env.DATE }}
          path: data/realtime/${{ env.DATE }}/
          retention-days: 7

      # ---- Optional: build master here, too ----
      - name: Cache GTFS static
        id: gtfs_cache
        uses: actions/cache@v4
        with:
          path: gtfs_static
          key: gtfs-static-v1
          restore-keys: |
            gtfs-static-

      - name: Prime static GTFS if missing
        timeout-minutes: 10
        run: |
          if ls gtfs_static/subway_all_*.zip 1>/dev/null 2>&1; then
            echo "Static GTFS already present."
          else
            echo "Refreshing static GTFSâ€¦"
            python pollers/mta_static_refresh.py
          fi

      - name: Run build_master (optional)
        timeout-minutes: 30
        env:
          PYTHONUNBUFFERED: "1"
          ALLOW_STATIC_REFRESH: "0"
          TRANSFER_WINDOW_MIN: "20"
          MISSED_THRESHOLD_MIN: "2"
        run: |
          trap 'echo "[signal] SIGTERM during build_master"; exit 143' SIGTERM
          python pollers/build_master.py

      - name: Upload curated (optional)
        timeout-minutes: 5
        uses: actions/upload-artifact@v4
        with:
          name: curated_today
          path: |
            data/curated/master_interface_dataset.csv
            data/curated/master_interface_dataset.parquet
            data/curated/master_interface_agg.csv
            data/curated/master_interface_agg.parquet
            data/curated/master_interface_dataset_summary.json
          retention-days: 7

