name: MTA Subway – Rolling Master to Google Drive

on:
  schedule:
    - cron: "*/10 10-15 * * 1-5"
    - cron: "*/10 20-23 * * 1-5"
    - cron: "*/10 0-1 * * 1-5"
    - cron: "0 12-23 * * 6,0"
    - cron: "0 0-2 * * 0,1"
  workflow_dispatch:
    inputs:
      missed_threshold_min:
        description: "Minutes needed to make a transfer (missed if gap < this)"
        required: false
        type: choice
        default: "2"
        options: ["1","2","3","5"]
      transfer_window_min:
        description: "Max window to consider a transfer (minutes)"
        required: false
        type: choice
        default: "20"
        options: ["10","15","20","25","30"]
      rt_max_files:
        description: "How many most-recent RT CSVs to consider"
        required: false
        default: "120"
        type: choice
        options: ["60","90","120","180","240"]
      service_date:
        description: "Override service date (YYYY-MM-DD); leave blank to infer"
        required: false
        default: ""
        type: string

concurrency:
  group: pipeline-${{ github.ref }}
  cancel-in-progress: false

jobs:
  subway_pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: read
      actions: read

    env:
      # Your exact rclone remote name and Drive folder (quotes allow spaces)
      GDRIVE_REMOTE_NAME: "googledrive"
      GDRIVE_DIR: "penn-station/curated"

    steps:
      - uses: actions/checkout@v4
      
      - name: Ensure gtfs_static exists
        run: mkdir -p gtfs_stat

      - uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install Python deps
        run: pip install -r requirements.txt

      - name: Sanity check repo layout
        run: |
          echo "[repo] top-level:"; ls -lh
          test -f pollers/mta_realtime_subway.py || { echo "::error::pollers/mta_realtime_subway.py missing"; exit 1; }
          test -f pollers/build_master.py        || { echo "::error::pollers/build_master.py missing"; exit 1; }

      # ===== rclone install & configure =====
      - name: Install rclone
        run: |
          curl -fsSL https://rclone.org/install.sh | sudo bash
          rclone version

      - name: Write rclone.conf from Base64 secret
        run: |
          mkdir -p ~/.config/rclone
          echo "${{ secrets.RCLONE_CONF_B64 }}" | base64 -d > ~/.config/rclone/rclone.conf
          chmod 600 ~/.config/rclone/rclone.conf
          rclone listremotes
          rclone about "${{ env.GDRIVE_REMOTE_NAME }}:" || (echo "Drive remote not reachable"; exit 1)

      # ===== PRE-SYNC: pull current master from Drive so we can append =====
      - name: Pull prior master from Drive
        run: |
          mkdir -p data/curated
          rclone lsd "${{ env.GDRIVE_REMOTE_NAME }}:${{ env.GDRIVE_DIR }}" || true
          rclone copy "${{ env.GDRIVE_REMOTE_NAME }}:${{ env.GDRIVE_DIR }}" data/curated \
            --include "master_interface_dataset.csv" \
            --include "master_interface_dataset.parquet" \
            --max-depth 1 --ignore-existing || true
          ls -lh data/curated || true

      # ===== Poll realtime =====
      - name: Run realtime poller
        env:
          MTA_API_KEY: ${{ secrets.MTA_API_KEY }}
        run: python pollers/mta_realtime_subway.py

      - name: Upload realtime CSVs (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: subway_realtime_csvs
          path: data/realtime/*.csv
          retention-days: 3

      # ===== Ensure static GTFS present =====
      - name: Cache GTFS static
        id: gtfs_cache
        uses: actions/cache@v4
        with:
          path: gtfs_static
          key: gtfs-static-v1
          restore-keys: gtfs-static-

      - name: Prime static GTFS if missing
        timeout-minutes: 10
        run: |
          if ls gtfs_static/subway_all_*.zip 1>/dev/null 2>&1; then
            echo "Static GTFS present."
          else
            echo "Refreshing static GTFS…"
            python pollers/mta_static_refresh.py
          fi

      # ===== Build & APPEND to rolling master =====
      - name: Build master & append
        env:
          PYTHONUNBUFFERED: "1"
          APPEND_TO_MASTER: "1"       # << always append moving forward
          ALLOW_STATIC_REFRESH: "0"
          RT_DIR: data/realtime
          RT_MAX_FILES: ${{ inputs.rt_max_files || '120' }}
          TRANSFER_WINDOW_MIN: ${{ inputs.transfer_window_min || '20' }}
          MISSED_THRESHOLD_MIN: ${{ inputs.missed_threshold_min || '2' }}
          SERVICE_DATE: ${{ inputs.service_date || '' }}
        run: |
          echo "[t0] starting build_master"
          python pollers/build_master.py
          echo "[t1] build_master finished"

      - name: Upload curated outputs (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: curated_outputs
          path: |
            data/curated/master_interface_dataset.csv
            data/curated/master_interface_dataset.parquet
          retention-days: 7

      # ===== POST-SYNC: push updated master back to Drive =====
      - name: Push updated master to Drive
        run: |
          rclone copy data/curated "${{ env.GDRIVE_REMOTE_NAME }}:${{ env.GDRIVE_DIR }}" \
            --include "master_interface_dataset.csv" \
            --include "master_interface_dataset.parquet" \
            --create-empty-src-dirs \
            --transfers 4 --checkers 8 \
            --drive-chunk-size 64M \
            --update --progress
