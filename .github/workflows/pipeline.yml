name: MTA Subway Static + Realtime + OneDrive

on:
  schedule:
    # Weekday peaks (America/New_York) with UTC buffers, every 10 minutes
    - cron: "*/10 10-15 * * 1-5"   # AM 06:00–11:59 ET (covers DST switch)
    - cron: "*/10 20-23 * * 1-5"   # PM 16:00–19:59 ET
    - cron: "*/10 0-1 * * 1-5"     # PM 20:00–21:59 ET
    # Weekly static refresh (Sun 03:10 UTC)
    - cron: "10 3 * * 0"
  workflow_dispatch: {}  # allow manual run

jobs:
  pipeline:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: pip install -r requirements.txt

      # Refresh static GTFS weekly
      - name: Refresh GTFS static (weekly)
        if: github.event.schedule == '10 3 * * 0'
        run: python pollers/mta_static_refresh.py

      # Pull realtime (protobuf) every scheduled run
      - name: Poll MTA Subway realtime
        run: python pollers/mta_realtime_subway.py

      # Build curated master
      - name: Build Master dataset
        run: python pollers/build_master.py

# Make sure the curated folder exists (first run may be empty)
- name: Ensure curated folder exists
  run: mkdir -p data/curated

# Install rclone on the GitHub runner
- name: Install rclone
  run: curl -fsSL https://rclone.org/install.sh | sudo bash

# Decode your Base64 rclone.conf secret into the runner
- name: Write rclone.conf from Base64 secret
  run: |
    mkdir -p ~/.config/rclone
    echo "${{ secrets.RCLONE_CONF_B64 }}" | base64 -d > ~/.config/rclone/rclone.conf
    chmod 600 ~/.config/rclone/rclone.conf

# Sanity check: confirm the remote exists and is reachable
# Replace 'googledrive' below if your remote name is different
- name: Verify rclone remote
  run: |
    rclone listremotes
    rclone lsd googledrive: || (echo "Remote 'googledrive' not found; check your remote name and secret" && exit 1)

# Copy curated outputs to Google Drive (My Drive/penn-station/curated)
# Change the destination path as you like
- name: Upload curated dataset to Google Drive
  run: |
    if [ -z "$(ls -A data/curated || true)" ]; then
      echo "Nothing to upload yet (data/curated is empty)."
    else
      rclone copy data/curated googledrive:penn-station/curated \
        --create-empty-src-dirs --checksum --transfers=4 --checkers=8
    fi

# (Optional) Also save the curated files as a workflow artifact for easy download
- name: Upload curated artifacts
  uses: actions/upload-artifact@v4
  with:
    name: curated_${{ github.run_id }}
    path: data/curated/*
    retention-days: 30

# --- END: Upload to Google Drive via rclone ---

